{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d9a69-b430-4ae9-94ac-7f04f362831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cftime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970c1c8-2547-4f91-82b6-0be3ce675d59",
   "metadata": {},
   "source": [
    "# Raster Plotting\n",
    "\n",
    "So far the plotting we have done has been to draw contours or color-filled contours, which both attempt to separate the data by putting higher values on one side of the contour and lower on the other. Matplotlib uses an algorith to find these separation points to be able to plot our data. And contours are great, but sometimes its just not the right fit for our data, or we wish to represent the gridded data in a more authentic raster format.\n",
    "\n",
    "Our gridded data is a version of what we call 'raster' data, which is \"any pixelated (or gridded) data where each pixel is associated with a specific geographical location\" (https://datacarpentry.org/organization-geospatial/01-intro-raster-data/). There are times when you may wish to represent the data distinctly as there individual grids and color them accordingly. This could be what you want for any form of gridded including satellite imagery. There are two main functions from Matplotlib that we could use, but we'll just focus on one for now, `pcolormesh`.\n",
    "\n",
    "But first, let's read in some data so we have something to plot. Here we are going to read in psuedo-surface air temperature data from the NCEP/NCAR Reanalysis dataset. (This data comes from a sigma surface near the ground, which is how we get the `sig995` in the name of the file.) We'll subset for a days in 2021 via the Xarray `.sel` method and using the datetime module to specify a data and time.\n",
    "\n",
    "Here is a link to a THREDDS server hosted by NOAA that contains a number of different types of datasets.\n",
    "\n",
    "https://psl.noaa.gov/thredds/catalog/Datasets/catalog.html\n",
    "\n",
    "Navigate to the `ncep.reanalysis` folder, then to the `surface` folder and select the `air.sig995.2021.nc` file. There are four different methods to access this data file and we want to use OPENDAP. Click that link and you'll be brought to a page that describes what is contained in the data file. What we are most interested in is the link at the top of the page in the box labeled Data URL. Copy that link to be able to use Xarray to read this data file remotely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eda5d3-8fbe-40c3-b7ef-8d75a5e410f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2021, 3, 8, 12)\n",
    "\n",
    "# Open Dataset\n",
    "ds_air = xr.open_dataset('')\n",
    "ds_air = ds_air.sel(time=date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b664d-64e3-4256-a067-12b4b2fb403d",
   "metadata": {},
   "source": [
    "## Color-fill Raster Imagery\n",
    "The Matplotlib function to fill in each grid cell with a different color is `pcolormesh`, which works similarly to our `contour` and `contourf` functions.\n",
    "\n",
    "```python\n",
    "ax.pcolormesh(x, y, Z, vmin=<minimum_value>, vmax=<maximum_value>, cmap=<colormap>, shading='auto')\n",
    "```\n",
    "\n",
    "The key difference here is that the levels are determined by setting two keyword arguments: `vmin` and `vmax`. These values are both inclusive for plotting meaning if you wanted to plot values from -50 to 50 you would set `vmin=-50` and `vmax=50`.  Additionally, you will always want to include the `shading='auto'` keyword arugment (as exampled above) to fill our grid cells appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a736b33-b23c-46a4-aec9-00eedce608e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(15, 15))\n",
    "ax = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "cf = ax.pcolormesh()\n",
    "\n",
    "plt.colorbar(cf, ax=ax, orientation='horizontal', pad=0, aspect=50)\n",
    "ax.coastlines()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32534aa-7f67-401b-a941-e5f0e9f224fe",
   "metadata": {},
   "source": [
    "Note that with this type of plotting (and due to our `shading='auto'` setting, we don't have the missing line of color around the Prime Meridian (0E). A nice little bonus for plotting our raster data instead of contouring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b876d-bcf6-475c-9503-7cc635465623",
   "metadata": {},
   "source": [
    "## Compute Anomaly Value\n",
    "Now that we have a raster-filled plot, let's take a different look at our data through computing an anomaly value.\n",
    "\n",
    "A value can be broken up into two parts, a mean and its anomaly.\n",
    "\n",
    "$a = \\bar{a} + a'$\n",
    "\n",
    "where $\\bar{a}$ is the mean value and $a'$ is the anomaly value.\n",
    "\n",
    "To solve for the anomaly value we add it to both sides and subtract our actual value from both sides to get\n",
    "\n",
    "$a' = a - \\bar{a}$\n",
    "\n",
    "If we want to compute the temperature anomaly values that we plotted above, we would need to read in (or compute) a long term mean (LTM) dataset. Lucky for us, NOAA provides such a file. We can read in the corresponding LTM data set, where the means are computed from the 1981-2010 values. There are multiple different files that contain this data, but what we want is the one that corresponds to the every six hour data that we have already read in, so we can subtract the mean value for that exact day and time combination.\n",
    "\n",
    "This is now \"derived\" data, meaning that it has been computed from other data and not a raw value.\n",
    "\n",
    "Here is a link to a THREDDS server hosted by NOAA that contains a number of different types of datasets.\n",
    "\n",
    "https://psl.noaa.gov/thredds/catalog/Datasets/catalog.html\n",
    "\n",
    "Navigate to the `ncep.reanalysis.derived` folder, then to the `surface` folder and select the `air.sig995.4Xday.1981-2010.ltm.nc` file. There are four different methods to access this data file and we want to use OPENDAP. Click that link and you'll be brought to a page that describes what is contained in the data file. What we are most interested in is the link at the top of the page in the box labeled Data URL. Copy that link to be able to use Xarray to read this data file remotely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df56d67-0d2a-4923-9efd-24b5dfa13ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ltm = xr.open_dataset('https://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis.derived/surface/air.sig995.4Xday.1981-2010.ltm.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7479037-e70b-41fc-8a12-2847f90839e3",
   "metadata": {},
   "source": [
    "### cftime\n",
    "The nature of long term mean (LTM) files are different from our regular daily value files. Here time is not associated with an individual day, but rather a set of 30 years (or some other set). Xarray therefore has difficulty interpreting the dates in the files and uses a different moduel, `cftime` to parse the time instead of Numpy. In order to access and subset our data we'll need to use that module as well.\n",
    "\n",
    "Let's begin by taking a look at what the time variable looks like from our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849ff2c-6a23-49b3-a05e-39f6d7911a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "223118de-faf1-4e00-90c9-0fe2fd3cadeb",
   "metadata": {},
   "source": [
    "Note how the time objects are `cftime.DatetimeGregorian` and are being referenced with year 1, but otherwise, the month, day, and hours are all as we would expect with a normal `datetime` object. Therefore, all we need is to select our time using the `cftime.DatetimeGregorian` function.\n",
    "\n",
    "```python\n",
    "ds = ds.sel(time=cftime.DatetimeGregorian(1, 5, 12, 18))\n",
    "```\n",
    "\n",
    "Assuming a standard dataset `ds` and using the default year 1 and specifying the month, day, and hour that we want to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0700f3-f533-47ec-b1dc-6afa6ae9fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ltm = ds_ltm.sel(time=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1f3fd-d4e1-4716-b2b8-7465da08eb0d",
   "metadata": {},
   "source": [
    "We can plot the LTM values to see what they look like in the same way we would plot the values from a given date/time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1a8c6-cf0f-498f-8e65-833cc96e81ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdf103b4-628a-4da7-be25-3675c9457691",
   "metadata": {},
   "source": [
    "Now that we have subset our data, let's actually compute the anomaly value. We need to do this on the actualy data arrays, so we would want to use `ds_air.air` for our actual values and `ds_ltm.air` for our LTM values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd57c1b-bc35-4a6f-9c52-59ab47fe95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c355f-2f32-4861-8608-e88f559e2749",
   "metadata": {},
   "source": [
    "We now have a new Xarray DataArray that contains our coordinate variables along with the computed anomaly values, still called `air` within the new DataArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72430023-b376-4ece-b61e-9329f9236a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3674625-3e59-457a-a81c-bda3dbcec99b",
   "metadata": {},
   "source": [
    "Now let's plot the anomaly values to see where on this particular day it was warmer and colder than the long term mean. To do this we want to use a diverging colormap (e.g., `plt.cm.bwr`) and set our `vmin` and `vmax` to be equal and opposite to place zero right in the center of the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15951a18-2c46-43d6-8efc-2c025782de25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e23e931-323b-46a0-97c7-fd555e17d6ec",
   "metadata": {},
   "source": [
    "## Compute and Plot Max/Min Values\n",
    "\n",
    "The where method from an Xarray DataArray makes it easy to find our maximum and minimum values over the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a81b11-9c57-4b14-a443-515849c7815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_anom = anomaly.where(anomaly == anomaly.max(), drop=True)[0][0]\n",
    "min_anom = anomaly.where(anomaly == anomaly.min(), drop=True)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390b41d-02eb-457b-9686-1b53b3ddeafc",
   "metadata": {},
   "source": [
    "But how do we plot these values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3fb483-ec9d-43ab-bdaa-a32f53b62ff3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting Max/Min Values with Transform\n",
    "\n",
    "To plot a marker at a given location we can use the `scatter` method:\n",
    "\n",
    "```python\n",
    "ax.scatter(x, y, s, marker='d', transform=ccrs.PlateCarree())\n",
    "```\n",
    "Here x is the x-coordinate location, y is the y-coordinate location, s is the size of the marker, and the keyword marker can be set to any of the valid Matplotlib markers.\n",
    "\n",
    "Matplotlib Scatter Documentation: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "\n",
    "Matplotlib Markers: https://matplotlib.org/stable/api/markers_api.html\n",
    "\n",
    "As long as your x and y values are latitude/longitude coordinate values, then you would want to use the `ccrs.PlateCarree()` projection for your transform keyword argument.\n",
    "\n",
    "To plot text at a given location on the plot we can use the `text` method:\n",
    "\n",
    "```python\n",
    "ax.text(x, y, string, transform=ccrs.PlateCarree())\n",
    "```\n",
    "Here x is the x-coordinate location, y is the y-coordinate location, and string is the text you wish to plot at the given point.\n",
    "\n",
    "Matplotlib Text Documentation: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.text.html\n",
    "\n",
    "Again, as long as your x and y values are latitude/longitude coordinate values, then you would want to use the `ccrs.PlateCarree()` projection for your transform keyword argument.\n",
    "\n",
    "Let's plot a black circle at the location of the maximum anomaly and label it Max and do the same for the minimum anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943c8bd-0ab1-4b5d-a4cb-18de23f01ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(15, 15))\n",
    "ax = plt.subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "cf = ax.pcolormesh(ds_air.lon, ds_air.lat, anomaly,\n",
    "                   vmin=-30, vmax=30, cmap=plt.cm.bwr, shading='auto')\n",
    "plt.colorbar(cf, orientation='horizontal', pad=0, aspect=50)\n",
    "\n",
    "# Add Maximum Value Marker and Text\n",
    "ax.scatter()\n",
    "ax.text()\n",
    "\n",
    "# Add Minimum Value Marker and Text\n",
    "ax.scatter()\n",
    "ax.text()\n",
    "\n",
    "ax.coastlines()\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "gl.bottom_labels = False\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064021f9-2e94-49d5-b278-4b14ea66775c",
   "metadata": {},
   "source": [
    "## Exercise #1\n",
    "Subset to a domain that only includes North America, plot the anomaly and find the maximum and minimum values over just that domain and plot them on the anomaly map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1cacd-1c2f-4638-b1c0-393161098be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
